{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQsuX0CsGQiq"
   },
   "source": [
    "# Space Invaders\n",
    "\n",
    "# Weights & Biases x Qualcomm - SpaceInvaders Challenge\n",
    "\n",
    "This notebook contains code for loading models from a file saved in a wandb run, and evaluating the model.\n",
    "\n",
    "For more details on the SpaceInvaders challenge, please visit the [competition website](https://app.wandb.ai/wandb/spaceinvaders-challenge/benchmark/).\n",
    "\n",
    "![](https://thumbs.gfycat.com/CookedFriendlyAntarcticfurseal-size_restricted.gif)\n",
    "\n",
    "## Running this notebook\n",
    "1. Click \"Open in playground\" to create a copy of this notebook for yourself.\n",
    "2. Save a copy in Google Drive for yourself.\n",
    "3. To enable a GPU, please click Edit > Notebook Settings. Change the \"hardware accelerator\" to GPU.\n",
    "4. Step through each section, pressing play on the code blocks to run the cells.\n",
    "5. Add your own model code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LlzpxEOsIePf"
   },
   "source": [
    "## Load the model\n",
    "\n",
    "Please replace the model file (`model.h5`) and run_path (`username/project_name/run_name`) with your submissions model file and run_path respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import io\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import argparse\n",
    "import torch\n",
    "from environment import atari_env\n",
    "from utils import read_config, setup_logger\n",
    "from model import A3Clstm\n",
    "from player_util import Agent\n",
    "import gym\n",
    "import glob\n",
    "import base64\n",
    "import logging\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from gym.wrappers import Monitor\n",
    "from torchsummary import summary \n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "from gym.wrappers.monitoring import video_recorder\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrVri-RnXD2B"
   },
   "outputs": [],
   "source": [
    "# restore a model file from a specific run by user \"lavanyashukla\" in project \"qualcomm\" from run \"mnswzdre\"\n",
    "fname = \"model.h5\"\n",
    "run_path=\"trained_model\"\n",
    "local_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# restore model\n",
    "api = wandb.Api()\n",
    "run = api.run(run_path)\n",
    "with run.file(fname).download(replace=True) as f:\n",
    "  local_path = f.name\n",
    "local_path_model = local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJ8AMc_zWCnS"
   },
   "source": [
    "## Setup and Preproceesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvHkMNUGGKCb"
   },
   "source": [
    "!pip install gym pyvirtualdisplay -qq\n",
    "!apt-get install -y xvfb python-opengl ffmpeg -qq\n",
    "!pip install xdpyinfo -qq\n",
    "!apt-get install x11-utils\n",
    "!apt-get update -qq\n",
    "!apt-get install cmake -qq\n",
    "!pip install --upgrade setuptools -qq\n",
    "!pip install ez_setup -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path_model = \"trained_models/model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hwt-wy0NWHuH"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIZiiAW6HTil"
   },
   "outputs": [],
   "source": [
    "# **** Caution: Do not modify this cell ****\n",
    "# initialize total reward across episodes\n",
    "cumulative_reward = 0\n",
    "episode = 0\n",
    "\n",
    "def evaluate(episodic_reward, reset=False):\n",
    "  '''\n",
    "  Takes in the reward for an episode, calculates the cumulative_avg_reward\n",
    "    and logs it in wandb. If episode > 100, stops logging scores to wandb.\n",
    "    Called after playing each episode. See example below.\n",
    "\n",
    "  Arguments:\n",
    "    episodic_reward - reward received after playing current episode\n",
    "  '''\n",
    "  global episode\n",
    "  global cumulative_reward\n",
    "  if reset:\n",
    "    cumulative_reward = 0\n",
    "    episode = 0\n",
    "    \n",
    "  episode += 1\n",
    "  print(\"Episode: %d\"%(episode))\n",
    "\n",
    "  # your models will be evaluated on 100-episode average reward\n",
    "  # therefore, we stop logging after 100 episodes\n",
    "  if (episode > 100):\n",
    "    print(\"Scores from episodes > 100 won't be logged in wandb.\")\n",
    "    return\n",
    "\n",
    "  # log total reward received in this episode to wandb\n",
    "  wandb.log({'episodic_reward': episodic_reward})\n",
    "\n",
    "  # add reward from this episode to cumulative_reward\n",
    "  cumulative_reward += episodic_reward\n",
    "\n",
    "  # calculate the cumulative_avg_reward\n",
    "  # this is the metric your models will be evaluated on\n",
    "  cumulative_avg_reward = cumulative_reward/episode\n",
    "\n",
    "  # log cumulative_avg_reward over all episodes played so far\n",
    "  wandb.log({'episodic_reward': episodic_reward})\n",
    "  wandb.log({'cumulative_avg_reward': cumulative_avg_reward})\n",
    "            \n",
    "  print(episodic_reward,cumulative_avg_reward)  \n",
    "\n",
    "  return cumulative_avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WDCVUIhxWL-n"
   },
   "source": [
    "## Play the game for 100 episodes, log cumulative average reward, for 5 different values of seed\n",
    "\n",
    "Please adjust this as needed to work with your model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHyYmf2AHWBn"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "\n",
    "class ARGS():\n",
    "    def __init__(self):\n",
    "        self.max_episode_length = 100000\n",
    "        self.skip_rate = 4\n",
    "        self.env_config = \"config.json\" \n",
    "\n",
    "args = ARGS()\n",
    "\n",
    "setup_json = read_config(args.env_config)\n",
    "env_conf = setup_json[\"SpaceInvaders\"]\n",
    "\n",
    "\n",
    "cumulative_avg_rewards = []\n",
    "\n",
    "\n",
    "saved_state = torch.load(local_path_model,map_location=lambda storage, loc: storage)\n",
    "\n",
    "# initialize environment\n",
    "env = atari_env(\"SpaceInvaders-v0\", env_conf, args)\n",
    "player = Agent(None, env, args, None)\n",
    "player.model = A3Clstm(player.env.observation_space.shape[0],\n",
    "                   player.env.action_space)\n",
    "\n",
    "\n",
    "\n",
    "player.model = player.model.to(device)\n",
    "\n",
    "player.model.load_state_dict(saved_state)\n",
    "player.model.eval()\n",
    "\n",
    "# initialize a new wandb run\n",
    "wandb.init(project=\"qualcomm\")\n",
    "\n",
    "# define hyperparameters\n",
    "wandb.config.episodes = args.max_episode_length\n",
    "wandb.config.batch_size = 20\n",
    "wandb.config.learning_rate = 0.0001\n",
    "\n",
    "wandb.save(\"*.py\")\n",
    "wandb.save(\"*.ipynb\")\n",
    "wandb.save(\"config.json\")\n",
    "\n",
    "\n",
    "# record gameplay video\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "player.env = gym.wrappers.Monitor(player.env, './video', force=True,mode='evaluation')\n",
    "\n",
    "\n",
    "for seed_ in [10, 50, 100, 200, 500]:\n",
    "  seed(seed_)\n",
    "  torch.manual_seed(seed_)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed_)\n",
    "  print(\"Seed: \",seed_)\n",
    "  episode = 0\n",
    "  \n",
    "\n",
    "  \n",
    "  # run for 100 episodes\n",
    "  # Note: Please adjust this as needed to work with your model architecture.\n",
    "  # Make sure you still call evaluate() with the reward received in each episode\n",
    "  for i in range(wandb.config.episodes):\n",
    "    # Set reward received in this episode = 0 at the start of the episode\n",
    "    episodic_reward = 0\n",
    "    reset = False\n",
    "\n",
    "    #vr = video_recorder.VideoRecorder(player.env,base_path=os.path.join(\"video\",\"{}.{}.video\".format(seed,i)))\n",
    "    #vr.capture_frame()\n",
    "    \n",
    "    # Start a random game\n",
    "    player.state = player.env.reset()\n",
    "    player.state = torch.from_numpy(player.state).float().to(device)\n",
    "\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        player.gpu_id = 0\n",
    "        \n",
    "    done = False\n",
    "    action_count = 0\n",
    "\n",
    "    # record a video of the game using wrapper\n",
    "    #if i==50:\n",
    "  \n",
    "    \n",
    "    while True:\n",
    "        player.action_test()\n",
    "\n",
    "        episodic_reward += player.reward\n",
    "        if player.done and not player.info:\n",
    "            player.state = player.env.reset()\n",
    "            player.state = torch.from_numpy(player.state).float().to(device)\n",
    "        elif player.info:\n",
    "            break\n",
    "    #print(\"reward\",episodic_reward)\n",
    "    # call evaluation function - takes in reward received after playing an episode\n",
    "    # calculates the cumulative_avg_reward over 100 episodes & logs it in wandb\n",
    "    if(i==0):\n",
    "      reset = True\n",
    "\n",
    "    cumulative_avg_reward = evaluate(episodic_reward, reset)\n",
    "\n",
    "    # your models will be evaluated on 100-episode average reward\n",
    "    # therefore, we stop logging after 100 episodes\n",
    "    if (i >= 99):\n",
    "      cumulative_avg_rewards.append(cumulative_avg_reward)\n",
    "      break\n",
    "\n",
    "    record_video = False\n",
    "    \n",
    "    #if i==50:\n",
    "    player.env.close() \n",
    "    #vr.close()\n",
    "    # render gameplay video\n",
    "    if (i %50 == 0):\n",
    "      mp4list = glob.glob('video/*.mp4')\n",
    "      if len(mp4list) > 0:\n",
    "        print(len(mp4list))\n",
    "        mp4 = mp4list[-1]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "\n",
    "        # log gameplay video in wandb\n",
    "        wandb.log({\"gameplays\": wandb.Video(mp4, fps=4, format=\"gif\")})\n",
    "\n",
    "        # display gameplay video\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"\" autoplay \n",
    "                    loop controls style=\"height: 400px;\">\n",
    "                    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(encoded.decode('ascii'))))\n",
    "player.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KV-irjWcYDAE"
   },
   "source": [
    "# Final score\n",
    "The final score is evaluated as the cumulative_avg_reward, averaged across 5 seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pKiJcC0WJ4W-"
   },
   "outputs": [],
   "source": [
    "print(\"Final score: \", np.mean(cumulative_avg_rewards))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpaceInvaders Evaluation Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
